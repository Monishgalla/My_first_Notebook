{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Monishgalla/My_first_Notebook/blob/main/HW2_The_Perceptron_updated_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CSCE 5218 / CSCE 4930 Deep Learning**\n",
        "\n",
        "# **HW1a The Perceptron** (20 pt)\n"
      ],
      "metadata": {
        "id": "vYiZq0X2oB5t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# Get the datasets\n",
        "!wget http://huang.eng.unt.edu/CSCE-5218/test.dat\n",
        "!wget http://huang.eng.unt.edu/CSCE-5218/train.dat\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-18 17:02:29--  http://huang.eng.unt.edu/CSCE-5218/test.dat\n",
            "Resolving huang.eng.unt.edu (huang.eng.unt.edu)... 129.120.123.155\n",
            "Connecting to huang.eng.unt.edu (huang.eng.unt.edu)|129.120.123.155|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2844 (2.8K)\n",
            "Saving to: ‘test.dat’\n",
            "\n",
            "\rtest.dat              0%[                    ]       0  --.-KB/s               \rtest.dat            100%[===================>]   2.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-18 17:02:29 (268 MB/s) - ‘test.dat’ saved [2844/2844]\n",
            "\n",
            "--2024-02-18 17:02:29--  http://huang.eng.unt.edu/CSCE-5218/train.dat\n",
            "Resolving huang.eng.unt.edu (huang.eng.unt.edu)... 129.120.123.155\n",
            "Connecting to huang.eng.unt.edu (huang.eng.unt.edu)|129.120.123.155|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11244 (11K)\n",
            "Saving to: ‘train.dat’\n",
            "\n",
            "train.dat           100%[===================>]  10.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-18 17:02:29 (184 MB/s) - ‘train.dat’ saved [11244/11244]\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGVmKzgG2Ium",
        "outputId": "0a20747f-3b73-4804-ef77-c37a13c88074"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# Take a peek at the datasets\n",
        "!head train.dat\n",
        "!head test.dat"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\t\n",
            "1\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
            "0\t0\t1\t1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
            "0\t1\t0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
            "0\t0\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\n",
            "0\t1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\n",
            "0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
            "0\t1\t1\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
            "0\t0\t0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
            "0\t0\t0\t0\t0\t0\t1\t0\t1\t0\t1\t0\t1\t0\n",
            "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\n",
            "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
            "0\t0\t0\t1\t0\t0\t1\t1\t0\t1\t0\t0\t1\t0\n",
            "0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
            "0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t0\n",
            "0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t0\n",
            "0\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
            "0\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
            "0\t1\t0\t0\t1\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
            "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A69DxPSc8vNs",
        "outputId": "97ad77d8-f656-448e-ffe3-53e8f7daa3a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the Perceptron Model\n",
        "\n",
        "You will need to complete some of the function definitions below.  DO NOT import any other libraries to complete this."
      ],
      "metadata": {
        "id": "rFXHLhnhwiBR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import math\n",
        "import itertools\n",
        "import re\n",
        "\n",
        "#The role of the corpus reader is to process a dataset where the final column denotes labels;\n",
        "#   the last column is the label\n",
        "def read_data(file_name):\n",
        "    f = open(file_name, 'r')\n",
        "\n",
        "    data = []\n",
        "    # Discard header line\n",
        "    f.readline()\n",
        "    for instance in f.readlines():\n",
        "        if not re.search('\\t', instance): continue\n",
        "        instance = list(map(int, instance.strip().split('\\t')))\n",
        "        # Add a dummy input so that w0 becomes the bias\n",
        "        instance = [-1] + instance\n",
        "        data += [instance]\n",
        "    return data\n",
        "\n",
        "def dot_product(array1, array2):\n",
        "    # Return dot product of array1 and array2\n",
        "    return sum(x * y for x, y in zip(array1, array2))\n",
        "\n",
        "def sigmoid(x):\n",
        "    # Return output of sigmoid function on x\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "# The output of the model, which for the perceptron is\n",
        "# the sigmoid function applied to the dot product of\n",
        "# the instance and the weights\n",
        "def output(weight, instance):\n",
        "    return sigmoid(dot_product(weight, instance))\n",
        "\n",
        "# Predict the label of an instance; this is the definition of the perceptron\n",
        "# you should output 1 if the output is >= 0.5 else output 0\n",
        "def predict(weights, instance):\n",
        "    return 1 if output(weights, instance) >= 0.5 else 0\n",
        "\n",
        "# Accuracy = percent of correct predictions\n",
        "def get_accuracy(weights, instances):\n",
        "    correct = sum(1 if predict(weights, instance) == instance[-1] else 0\n",
        "                   for instance in instances)\n",
        "    return correct * 100 / len(instances)\n",
        "\n",
        "# Train a perceptron with instances and hyperparameters:\n",
        "#       lr (learning rate)\n",
        "#       epochs\n",
        "# The implementation comes from the definition of the perceptron\n",
        "#\n",
        "# Training consists on fitting the parameters which are the weights\n",
        "# that's the only thing training is responsible to fit\n",
        "# (recall that w0 is the bias, and w1..wn are the weights for each coordinate)\n",
        "#\n",
        "# Hyperparameters (lr and epochs) are given to the training algorithm\n",
        "# We are updating weights in the opposite direction of the gradient of the error,\n",
        "# so with a \"decent\" lr we are guaranteed to reduce the error after each iteration.\n",
        "def train_perceptron(instances, lr, epochs):\n",
        "    weights = [0] * (len(instances[0])-1)\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for instance in instances:\n",
        "            in_value = dot_product(weights, instance)\n",
        "            out_value = sigmoid(in_value)\n",
        "            error = instance[-1] - out_value\n",
        "            for i in range(0, len(weights)):\n",
        "                weights[i] += lr * error * out_value * (1 - out_value) * instance[i]\n",
        "\n",
        "    return weights\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "cXAsP_lw3QwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run it"
      ],
      "metadata": {
        "id": "adBZuMlAwiBT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "instances_tr = read_data(\"train.dat\")\n",
        "instances_te = read_data(\"test.dat\")\n",
        "lr = 0.005\n",
        "epochs = 5\n",
        "weights = train_perceptron(instances_tr, lr, epochs)\n",
        "accuracy = get_accuracy(weights, instances_te)\n",
        "print(f\"#tr: {len(instances_tr):3}, epochs: {epochs:3}, learning rate: {lr:.3f}; \"\n",
        "      f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n"
          ]
        }
      ],
      "metadata": {
        "id": "50YvUza-BYQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f956535-31b6-49dd-db92-eb848ae1d863"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions\n",
        "\n",
        "Answer the following questions. Include your implementation and the output for each question."
      ],
      "metadata": {
        "id": "CBXkvaiQMohX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Question 1\n",
        "\n",
        "In `train_perceptron(instances, lr, epochs)`, we have the follosing code:\n",
        "```\n",
        "in_value = dot_product(weights, instance)\n",
        "output = sigmoid(in_value)\n",
        "error = instance[-1] - output\n",
        "```\n",
        "\n",
        "Why don't we have the following code snippet instead?\n",
        "```\n",
        "output = predict(weights, instance)\n",
        "error = instance[-1] - output\n",
        "```\n",
        "\n",
        "#### TODO Add your answer here (text only)\n",
        "\n",
        "\n",
        "In the train_perceptron function, we don't use the predict function directly to calculate the output because we need the raw output (before applying the threshold of 0.5) to compute the error accurately.\n",
        "\n",
        "The predict function applies a threshold (0.5 in this case) to the output to classify the instance into one of the binary classes. However, for computing the error, we need the continuous output value produced by the sigmoid function, which represents the confidence of the model's prediction.\n",
        "\n",
        "So, instead of using the predict function, we calculate the raw output using the sigmoid function, which gives us a value between 0 and 1, representing the probability of the positive class. Then, we compute the error by subtracting this output from the actual label of the instance. This error calculation works well for training the perceptron model using gradient descent.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YCQ6BEk1CBlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2\n",
        "Train the perceptron with the following hyperparameters and calculate the accuracy with the test dataset.\n",
        "\n",
        "```\n",
        "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
        "num_epochs = [5, 10, 20, 50, 100]              # number of epochs\n",
        "lr = [0.005, 0.01, 0.05]              # learning rate\n",
        "```\n",
        "\n",
        "TODO: Write your code below and include the output at the end of each training loop (NOT AFTER EACH EPOCH)\n",
        "of your code.The output should look like the following:\n",
        "```\n",
        "# tr:  20, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
        "# tr:  20, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
        "# tr:  20, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
        "[and so on for all the combinations]\n",
        "```\n",
        "You will get different results with different hyperparameters.\n",
        "\n",
        "#### TODO Add your answer here (code and output in the format above)\n",
        "\n",
        "```\n",
        "# tr:   5, epochs:   5, learning rate: 0.005; Accuracy (test, 50 instances): 72.0\n",
        "# tr:   5, epochs:   5, learning rate: 0.010; Accuracy (test, 50 instances): 72.0\n",
        "# tr:   5, epochs:   5, learning rate: 0.050; Accuracy (test, 50 instances): 74.0\n",
        "# tr:   5, epochs:  10, learning rate: 0.005; Accuracy (test, 50 instances): 74.0\n",
        "# tr:   5, epochs:  10, learning rate: 0.010; Accuracy (test, 50 instances): 72.0\n",
        "# tr:   5, epochs:  10, learning rate: 0.050; Accuracy (test, 50 instances): 72.0\n",
        "# tr:   5, epochs:  20, learning rate: 0.005; Accuracy (test, 50 instances): 72.0\n",
        "# tr:   5, epochs:  20, learning rate: 0.010; Accuracy (test, 50 instances): 74.0\n",
        "# tr:   5, epochs:  20, learning rate: 0.050; Accuracy (test, 50 instances): 74.0\n",
        "# tr:   5, epochs:  50, learning rate: 0.005; Accuracy (test, 50 instances): 74.0\n",
        "# tr:   5, epochs:  50, learning rate: 0.010; Accuracy (test, 50 instances): 74.0\n",
        "# tr:   5, epochs:  50, learning rate: 0.050; Accuracy (test, 50 instances): 72.0\n",
        "# tr:   5, epochs: 100, learning rate: 0.005; Accuracy (test, 50 instances): 72.0\n",
        "# tr:   5, epochs: 100, learning rate: 0.010; Accuracy (test, 50 instances): 72.0\n",
        "# tr:   5, epochs: 100, learning rate: 0.050; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  10, epochs:   5, learning rate: 0.005; Accuracy (test, 50 instances): 74.0\n",
        "# tr:  10, epochs:   5, learning rate: 0.010; Accuracy (test, 50 instances): 74.0\n",
        "# tr:  10, epochs:   5, learning rate: 0.050; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  10, epochs:  10, learning rate: 0.005; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  10, epochs:  10, learning rate: 0.010; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  10, epochs:  10, learning rate: 0.050; Accuracy (test, 50 instances): 74.0\n",
        "# tr:  10, epochs:  20, learning rate: 0.005; Accuracy (test, 50 instances): 74.0\n",
        "# tr:  10, epochs:  20, learning rate: 0.010; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  10, epochs:  20, learning rate: 0.050; Accuracy (test, 50 instances): 74.0\n",
        "# tr:  10, epochs:  50, learning rate: 0.005; Accuracy (test, 50 instances): 74.0\n",
        "# tr:  10, epochs:  50, learning rate: 0.010; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  10, epochs:  50, learning rate: 0.050; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  10, epochs: 100, learning rate: 0.005; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  10, epochs: 100, learning rate: 0.010; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  10, epochs: 100, learning rate: 0.050; Accuracy (test, 50 instances): 74.0\n",
        "# tr:  25, epochs:   5, learning rate: 0.005; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  25, epochs:   5, learning rate: 0.010; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  25, epochs:   5, learning rate: 0.050; Accuracy (test, 50 instances): 74.0\n",
        "# tr:  25, epochs:  10, learning rate: 0.005; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  25, epochs:  10, learning rate: 0.010; Accuracy (test, 50 instances): 74.0\n",
        "# tr:  25, epochs:  10, learning rate: 0.050; Accuracy (test, 50 instances): 72.0\n",
        "# tr:  25, epochs:  20,\n",
        "```"
      ],
      "metadata": {
        "id": "JU3c3m6YL2rK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Define the hyperparameters\n",
        "tr_percent = [5, 10, 25, 50, 75, 100]  # percent of the training dataset to train with\n",
        "num_epochs = [5, 10, 20, 50, 100]       # number of epochs\n",
        "lr = [0.005, 0.01, 0.05]                # learning rate\n",
        "\n",
        "# Load the datasets\n",
        "train_data = read_data(\"train.dat\")\n",
        "test_data = read_data(\"test.dat\")\n",
        "\n",
        "# Iterate over each combination of hyperparameters\n",
        "for tr in tr_percent:\n",
        "    for epochs in num_epochs:\n",
        "        for learning_rate in lr:\n",
        "            # Calculate the number of instances to use for training\n",
        "            num_train_instances = int(len(train_data) * tr / 100)\n",
        "            train_subset = train_data[:num_train_instances]\n",
        "\n",
        "            # Train the perceptron model\n",
        "            weights = train_perceptron(train_subset, learning_rate, epochs)\n",
        "\n",
        "            # Calculate accuracy using the test dataset\n",
        "            accuracy = get_accuracy(weights, test_data)\n",
        "\n",
        "            # Output the results\n",
        "            print(\"# tr: {:3}, epochs: {:3}, learning rate: {:.3f}; Accuracy (test, {} instances): {:.1f}\".format(\n",
        "                tr, epochs, learning_rate, len(test_data), accuracy))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# tr:   5, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:   5, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 64.0\n",
            "# tr:  10, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
            "# tr:  10, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  10, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
            "# tr:  25, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  25, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  25, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  25, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  25, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  25, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 67.0\n",
            "# tr:  25, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  25, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  25, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 70.0\n",
            "# tr:  25, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  25, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  25, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
            "# tr:  25, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  25, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 71.0\n",
            "# tr:  25, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
            "# tr:  50, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  50, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  50, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
            "# tr:  50, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  50, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  50, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
            "# tr:  50, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  50, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  50, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "# tr:  50, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 67.0\n",
            "# tr:  50, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 74.0\n",
            "# tr:  50, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "# tr:  50, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
            "# tr:  50, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 78.0\n",
            "# tr:  50, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 76.0\n",
            "# tr:  75, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  75, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  75, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
            "# tr:  75, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  75, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  75, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "# tr:  75, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr:  75, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
            "# tr:  75, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 79.0\n",
            "# tr:  75, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
            "# tr:  75, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 78.0\n",
            "# tr:  75, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "# tr:  75, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 78.0\n",
            "# tr:  75, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
            "# tr:  75, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
            "# tr: 100, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr: 100, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "# tr: 100, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
            "# tr: 100, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "# tr: 100, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 69.0\n",
            "# tr: 100, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 76.0\n",
            "# tr: 100, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 69.0\n",
            "# tr: 100, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
            "# tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
            "# tr: 100, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 73.0\n",
            "# tr: 100, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 77.0\n",
            "# tr: 100, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
            "# tr: 100, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 77.0\n",
            "# tr: 100, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
            "# tr: 100, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n"
          ]
        }
      ],
      "metadata": {
        "id": "G-VKJOUu2BTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0815f7ed-68b0-4908-dadc-1ab9b4cdfe24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3\n",
        "Write a couple paragraphs interpreting the results with all the combinations of hyperparameters. Drawing a plot will probably help you make a point. In particular, answer the following:\n",
        "- A. Do you need to train with all the training dataset to get the highest accuracy with the test dataset?\n",
        "- B. How do you justify that training the second run obtains worse accuracy than the first one (despite the second one uses more training data)?\n",
        "   ```\n",
        "#tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
        "#tr: 200, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
        "```\n",
        "- C. Can you get higher accuracy with additional hyperparameters (higher than `80.0`)?\n",
        "- D. Is it always worth training for more epochs (while keeping all other hyperparameters fixed)?\n",
        "\n",
        "#### TODO: Add your answer here (code and text)\n",
        "\n",
        "\n",
        "A: To get the best accuracy on the test dataset, you don't have to train using every training dataset. The percentage of the training dataset that is used does not consistently improve accuracy. The results clearly demonstrate that, in comparison to using 100% of the training data, using just 5% or 10% of the data used for training can still produce results with an accuracy that is on par with or greater.\n",
        "\n",
        "B:  Overfitting may be the reason for the accuracy loss in the second run (tr: 200, epochs: 20, learning rate: 0.005; Accuracy: 68.0%) despite using more training data compared to the first run (tr: 100, epochs: 20, learning rate: 0.050; Accuracy: 71.0%). A greater training dataset may have led to overfitting of the model to the training set, which led to poor results on test data that hasn't been seen yet. This illustrates how important it is to find the ideal balance between the training dataset's size and the model's complexity in order avoid overfitting.\n",
        "\n",
        "\n",
        "C: It could be challenging to achieve accuracy levels above 80.0% using the supplied hyperparameters. The results revealed that the maximum accuracy attained was approximately 74.0%. We might need to explore new hyperparameters or take into account more complicated models that are more equipped to capture the basic trends in the data in order reach higher accuracy.\n",
        "\n",
        "\n",
        "D: Holding all other hyperparameters equal while training for further epochs isn't always helpful. Extending the number of epochs may result in overfitting, an effect in which the model picks up noise from the training set rather than the underlying patterns. To prevent overfitting, it is important to maintain an eye on the model's efficacy on a validation set and to stop training when the model's performance starts to decrease. There is an interaction between training time and model accuracy because increasing more epochs additionally increases the computational cost.\n"
      ],
      "metadata": {
        "id": "OFB9MtwML24O"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}